import os
from typing import List, Optional
from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    UnstructuredExcelLoader,
    CSVLoader,
    Docx2txtLoader,
    UnstructuredWordDocumentLoader
)


from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import (
    PyPDFLoader, TextLoader, CSVLoader,
    UnstructuredExcelLoader, Docx2txtLoader,
    UnstructuredWordDocumentLoader
)

import json



class DocumentLoader:
    # å®šä¹‰éœ€è¦å¿½ç•¥çš„æ–‡ä»¶
    IGNORED_EXTENSIONS = {'.json', '.log', '.tmp', '.bak', '.db', '.sqlite'}
    IGNORED_FILENAMES = {'knowledge_data.json', 'metadata.json', 'config.json'}
    IGNORED_DIRECTORIES = {'vectorstore', '__pycache__', '.git', 'node_modules'}


    def __init__(self, docs_dir: Optional[str] = None, chunk_size: Optional[int] = None, 
             chunk_overlap: Optional[int] = None):
        """
        åˆå§‹åŒ–DocumentLoader
        
        Args:
            docs_dir: çŸ¥è¯†åº“ç›®å½•è·¯å¾„ï¼Œç”¨äºè¯»å–é…ç½®
            chunk_size: æ–‡æ¡£å—å¤§å°ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆçº§é«˜äºé…ç½®æ–‡ä»¶ï¼‰
            chunk_overlap: æ–‡æ¡£å—é‡å å¤§å°ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆçº§é«˜äºé…ç½®æ–‡ä»¶ï¼‰
        """
        # ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°
        config = self._load_config(docs_dir) if docs_dir else {}
        print(f"æ–‡æ¡£åˆå§‹åŒ–æ“ä½œè¯»å–åˆ°çš„æ–‡ä»¶è·¯å¾„ï¼š{docs_dir}")
        print("è¯»å–çš„chunk_size:",config.get("chunk_size"))
        print("è¯»å–çš„chunk_overlap:",config.get("chunk_overlap"))


        # å‚æ•°ä¼˜å…ˆçº§ï¼šå‡½æ•°å‚æ•° > é…ç½®æ–‡ä»¶ > é»˜è®¤å€¼
        self.chunk_size = chunk_size or config.get("chunk_size", 1000)
        self.chunk_overlap = chunk_overlap or config.get("chunk_overlap", 200)
        
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            separators=["\n\n", "\n", " ", ""]
        )
        """
        ä¼˜å…ˆæŒ‰æ®µè½ï¼ˆåŒæ¢è¡Œç¬¦ï¼‰åˆ†å‰²
        å…¶æ¬¡æŒ‰å•ä¸ªæ¢è¡Œç¬¦åˆ†å‰²
        ç„¶åæŒ‰ç©ºæ ¼åˆ†å‰²
        æœ€ååœ¨å¿…è¦æ—¶ç›´æ¥åˆ†å‰²å­—ç¬¦
        """



    def _load_config(self, docs_dir: str) -> dict:
        """
        ä»çŸ¥è¯†åº“ç›®å½•ä¸‹çš„knowledge_data.jsonåŠ è½½é…ç½®
        
        Args:
            docs_dir: çŸ¥è¯†åº“ç›®å½•è·¯å¾„
            
        Returns:
            é…ç½®å­—å…¸ï¼ŒåŒ…å«chunk_sizeå’Œchunk_overlap
        """
        config_path = os.path.join(docs_dir, "knowledge_data.json")
        config = {}
        
        try:
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # æå–æ–‡æ¡£åˆ†å—é…ç½®
                    config["chunk_size"] = data.get("chunk_size", 1000)
                    config["chunk_overlap"] = data.get("chunk_overlap", 200)
                    print(f"ä» {config_path} åŠ è½½åˆ†å—é…ç½®: chunk_size={config['chunk_size']}, "
                        f"chunk_overlap={config['chunk_overlap']}")
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        
        return config




    def should_skip_file(self, file_path: str) -> tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶å¤„ç†
        
        Returns:
            (should_skip: bool, reason: str)
        """
        filename = os.path.basename(file_path)
        file_extension = os.path.splitext(file_path)[1].lower()
        
        # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ…å«éœ€è¦å¿½ç•¥çš„ç›®å½•
        path_parts = os.path.normpath(file_path).split(os.sep)
        for ignored_dir in self.IGNORED_DIRECTORIES:
            if ignored_dir in path_parts:
                return True, f"ä½äºå¿½ç•¥ç›®å½• '{ignored_dir}' ä¸­"
        
        # è·³è¿‡ä¸´æ—¶æ–‡ä»¶
        if filename.startswith('~$'):
            return True, "ä¸´æ—¶æ–‡ä»¶"
            
        # è·³è¿‡ç‰¹å®šæ–‡ä»¶å
        if filename in self.IGNORED_FILENAMES:
            return True, "é…ç½®æ–‡ä»¶"
            
        # è·³è¿‡ç‰¹å®šæ‰©å±•å
        if file_extension in self.IGNORED_EXTENSIONS:
            return True, "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"
            
        return False, ""
    
    def load_document(self, file_path: str, is_google_drive: bool = False) -> List:
        """
        Load and split a document based on its file type
        
        Args:
            file_path: Local file path or Google Drive file ID
            is_google_drive: Whether the file is from Google Drive
        """
        # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶
        should_skip, skip_reason = self.should_skip_file(file_path)
        if should_skip:
            raise ValueError(f"Skipped file ({skip_reason}): {os.path.basename(file_path)}")
        
        if is_google_drive:
            if not self.google_drive_enabled:
                raise ValueError("Google Drive integration is not configured")
            try:
                file_path = self.google_drive_loader.download_file(file_path)
            except (IOError, OSError) as e:
                raise IOError(f"Error downloading from Google Drive: {str(e)}") from e
                
        file_extension = os.path.splitext(file_path)[1].lower()
        
        # ğŸ”§ æ”¹è¿›ï¼šæ›´æ˜ç¡®çš„é”™è¯¯å¤„ç†
        if file_extension == '.pdf':
            loader = PyPDFLoader(file_path)
        elif file_extension in ['.txt', '.md']:
            try:
                # 1. è§„èŒƒåŒ–è·¯å¾„ï¼Œè§£å†³åæ–œæ é—®é¢˜
                normalized_path = os.path.normpath(file_path)
                # 2. é¦–å…ˆå°è¯•utf-8ç¼–ç 
                loader = TextLoader(normalized_path, encoding='utf-8')
                documents = loader.load()
            except UnicodeDecodeError:
                # 3. å¦‚æœutf-8å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨latin-1ç¼–ç ï¼ˆæ›´å®½å®¹çš„ç¼–ç ï¼‰
                loader = TextLoader(normalized_path, encoding='latin-1')
                documents = loader.load()
            except Exception as e:
                # 4. å…¶ä»–é”™è¯¯çš„è¯¦ç»†æ—¥å¿—
                print(f"Error loading text file {file_path}: {str(e)}")
                raise ValueError(f"Error loading {file_path}: {str(e)}")
        elif file_extension in ['.xlsx', '.xls']:
            loader = UnstructuredExcelLoader(file_path)
        elif file_extension == '.csv':
            loader = CSVLoader(file_path)
        elif file_extension == '.docx':
            try:
                loader = Docx2txtLoader(file_path)
            except (ImportError, IOError):
                loader = UnstructuredWordDocumentLoader(file_path)
        else:
            raise ValueError(f"Unsupported file type: {file_extension}")
            
        # ä»…å½“å°šæœªåŠ è½½documentsæ—¶æ‰è°ƒç”¨loader.load()
        if 'documents' not in locals():
            documents = loader.load()
        return self.text_splitter.split_documents(documents)
