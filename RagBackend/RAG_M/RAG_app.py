from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from functools import lru_cache
import os
from pathlib import Path
from dotenv import load_dotenv
import json
import asyncio

from fastapi.responses import StreamingResponse
import io
import contextlib


# å¯¼å…¥RAG_MåŸæœ‰çš„æ ¸å¿ƒç»„ä»¶
import sys
project_root = str(Path(__file__).parent)
sys.path.append(project_root)

from src.rag.rag_pipeline import RAGPipeline
from src.vectorstore.vector_store import VectorStoreManager

load_dotenv()

router = APIRouter()

class QueryRequest(BaseModel):
    query: str
    docs_dir: str = None  # å¯é€‰çš„æ–‡ä»¶å¤¹è·¯å¾„

class IngestRequest(BaseModel):
    docs_dir: str
    



@contextlib.contextmanager
def capture_stdout():
    stdout_buffer = io.StringIO()
    original_stdout = sys.stdout
    
    # åˆ›å»ºä¸€ä¸ªåŒé‡è¾“å‡ºçš„ç±»
    class DualOutput:
        def __init__(self, original, buffer):
            self.original = original
            self.buffer = buffer
            
        def write(self, text):
            self.original.write(text)
            self.buffer.write(text)
            
        def flush(self):
            self.original.flush()
            self.buffer.flush()
    
    sys.stdout = DualOutput(original_stdout, stdout_buffer)
    try:
        yield stdout_buffer
    finally:
        sys.stdout = original_stdout



@lru_cache()
def get_rag_pipeline(vectorstore_path: str = None):
    """åˆå§‹åŒ–RAGç®¡é“"""
    # ä½¿ç”¨ä¼ å…¥çš„è·¯å¾„æˆ–ç¯å¢ƒå˜é‡ä¸­çš„è·¯å¾„
    vectorstore_path = vectorstore_path or os.getenv("VECTORSTORE_PATH")
    if not vectorstore_path:
        raise ValueError("Vector store path not provided and VECTORSTORE_PATH not set in environment")
    
    vector_store_manager = VectorStoreManager()
    vectorstore = vector_store_manager.load_vectorstore(
        vectorstore_path,
        trust_source=True
    )
    print(f"åˆå§‹åŒ–RAGç®¡é“ï¼Œä½¿ç”¨æ¨¡å‹: {os.getenv('MODEL')}ï¼Œå‘é‡å­˜å‚¨è·¯å¾„: {vectorstore_path}")
    return RAGPipeline(os.getenv("MODEL"), vectorstore)



@router.post("/RAG_query")
async def process_query(query_body: QueryRequest):
    """RAGæ™ºèƒ½æŸ¥è¯¢æ¥å£ - æ”¯æŒæŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„è¿›è¡ŒæŸ¥è¯¢ï¼Œä»¥æµå¼æ–¹å¼è¿”å›ç»“æœ"""
    
    async def generate():
        try:
            yield f"data: å¼€å§‹å¤„ç†æŸ¥è¯¢: {query_body.query}\n\n"
            
            # ç»Ÿä¸€ä½¿ç”¨ä¸€ä¸ªVectorStoreManagerå®ä¾‹
            vector_store_manager = VectorStoreManager(docs_dir=query_body.docs_dir)
            
            # ç¡®å®šå‘é‡å­˜å‚¨è·¯å¾„
            if query_body.docs_dir:
                vectorstore_path = os.path.join(query_body.docs_dir, "vectorstore")
                yield f"data: ä½¿ç”¨è‡ªå®šä¹‰å‘é‡å­˜å‚¨è·¯å¾„: {vectorstore_path}\n\n"
                
                if not os.path.exists(vectorstore_path):
                    error_msg = f"å‘é‡å­˜å‚¨è·¯å¾„ä¸å­˜åœ¨: {vectorstore_path}"
                    yield f"data: ERROR: {error_msg}\n\n"
                    raise HTTPException(status_code=404, detail=f"Vector store not found at {vectorstore_path}")
                
                yield "data: æ­£åœ¨åŠ è½½å‘é‡å­˜å‚¨...\n\n"
                vectorstore = vector_store_manager.load_vectorstore(
                    vectorstore_path,
                    trust_source=True
                )
                yield "data: å‘é‡å­˜å‚¨åŠ è½½å®Œæˆ\n\n"
            else:
                yield "data: ä½¿ç”¨é»˜è®¤å‘é‡å­˜å‚¨\n\n"
                vectorstore_path = os.getenv("VECTORSTORE_PATH")
                vectorstore = vector_store_manager.load_vectorstore(
                    vectorstore_path,
                    trust_source=True
                )
                yield "data: é»˜è®¤å‘é‡å­˜å‚¨åŠ è½½å®Œæˆ\n\n"
            
            # åˆå§‹åŒ–RAGç®¡é“
            yield "data: åˆå§‹åŒ–RAGç®¡é“...\n\n"
            rag = RAGPipeline(os.getenv("MODEL"), vectorstore)
            yield "data: RAGç®¡é“åˆå§‹åŒ–å®Œæˆ\n\n"
            
            # å¤„ç†æŸ¥è¯¢
            yield "data: å¼€å§‹å¤„ç†æŸ¥è¯¢...\n\n"
            
            # è·å–ç›¸å…³æ–‡æ¡£
            yield "data: æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...\n\n"
            retriever = vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 3}
            )
            docs = retriever.get_relevant_documents(query_body.query)
            yield f"data: æ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£\n\n"
            
            # å¤„ç†æŸ¥è¯¢å¹¶è·å–ç»“æœ
            result = rag.process_query(query_body.query)
            
            # åˆ†æ®µè¿”å›å›ç­”å†…å®¹
            # å‡è®¾æˆ‘ä»¬è¦æŒ‰æ®µè½åˆ†å‰²
            paragraphs = result["answer"].split('\n\n')
            
            yield "data: æ­£åœ¨ç”Ÿæˆå›ç­”...\n\n"
            for paragraph in paragraphs:
                if paragraph.strip():
                    yield f"data: {paragraph.strip()}\n\n"
                    # å¯é€‰ï¼šæ·»åŠ çŸ­æš‚å»¶è¿Ÿä»¥æ¨¡æ‹Ÿæµå¼è¾“å‡ºæ•ˆæœ
                    await asyncio.sleep(0.1)
            
            # è¿”å›æ¥æºä¿¡æ¯
            yield "data: å‚è€ƒæ¥æº:\n\n"
            for i, source in enumerate(result["sources"], 1):
                # ä¿®å¤: æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨ï¼Œæˆ–ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼è®¿é—®æ•°æ®
                if 'source' in source:
                    yield f"data: {i}. {source['source']}\n\n"
                else:
                    # å¦‚æœæ²¡æœ‰sourceé”®ï¼Œå°è¯•ä½¿ç”¨å…¶ä»–å¯èƒ½çš„é”®æˆ–æ˜¾ç¤ºæ‰€æœ‰å…ƒæ•°æ®
                    source_text = source.get('path', source.get('file_path', str(source)))
                    yield f"data: {i}. {source_text}\n\n"
            
            # å‘é€å®Œæ•´ç»“æœä½œä¸ºJSONä»¥ä¾¿å®¢æˆ·ç«¯å¯ä»¥è·å–ç»“æ„åŒ–æ•°æ®
            final_result = {
                "answer": result["answer"],
                "sources": result["sources"],
                "vectorstore_path": vectorstore_path
            }
            yield f"data: COMPLETE: {json.dumps(final_result, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            import traceback
            error_trace = traceback.format_exc()
            error_msg = f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}\n{error_trace}"
            yield f"data: ERROR: {error_msg}\n\n"
            print(f"[ERROR] {error_msg}")
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
    )



@router.post("/ingest")
async def ingest_documents(ingest_body: IngestRequest):
    """æ–‡æ¡£å¯¼å…¥æ¥å£ - æ›¿ä»£åŸæ¥çš„ingest_documents.pyåŠŸèƒ½"""
    def generate():
        with capture_stdout() as stdout_buffer:
            print(f"Starting document ingestion from directory: {ingest_body.docs_dir}")
            try:
                from src.ingestion.document_loader import DocumentLoader
                from src.vectorstore.vector_store import VectorStoreManager
                
                # ä½¿ç”¨çŸ¥è¯†åº“ç›®å½•ä¸­çš„é…ç½®
                vector_store_manager = VectorStoreManager(docs_dir=ingest_body.docs_dir)
                documents = []

                # åŠ¨æ€ç¡®å®šå‘é‡å­˜å‚¨è·¯å¾„
                vectorstore_path = ingest_body.docs_dir + "/vectorstore"
                print(f"Using vector store path: {vectorstore_path}")
                yield f"data: Using vector store path: {vectorstore_path}\n\n"
                
                # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
                if not os.path.exists(ingest_body.docs_dir):
                    print(f"Directory does not exist: {ingest_body.docs_dir}")
                    yield f"data: Directory does not exist: {ingest_body.docs_dir}\n\n"
                    raise ValueError(f"Directory does not exist: {ingest_body.docs_dir}")
                
                # åˆå§‹åŒ–åŠ è½½å™¨å’Œå‘é‡å­˜å‚¨ç®¡ç†å™¨
                print("Initializing DocumentLoader")
                yield "data: Initializing DocumentLoader\n\n"
                #loader = DocumentLoader()
                loader = DocumentLoader(docs_dir=ingest_body.docs_dir)
                #vector_store_manager = VectorStoreManager() #åˆ é™¤é»˜è®¤é¡¹
                documents = []
                
                # ç»Ÿè®¡ä¿¡æ¯
                processed_count = 0
                skipped_count = 0
                error_count = 0
                
                # é¦–å…ˆéå†å¹¶å¤„ç†æ‰€æœ‰æ–‡ä»¶
                print("Walking through directory to process files")
                yield "data: Walking through directory to process files\n\n"
                
                for root, dirs, files in os.walk(ingest_body.docs_dir):
                    
                    # ğŸ”§ æ–°å¢ï¼šåœ¨éå†å‰è¿‡æ»¤æ‰éœ€è¦å¿½ç•¥çš„ç›®å½•
                    dirs[:] = [d for d in dirs if d not in loader.IGNORED_DIRECTORIES]
                    
                    # è·³è¿‡å·²ç»æ˜¯vectorstoreç›®å½•çš„æƒ…å†µ
                    if 'vectorstore' in os.path.basename(root):
                        print(f"Skipping vectorstore directory: {root}")
                        yield f"data: Skipping vectorstore directory: {root}\n\n"
                        continue
                    
                    
                    
                    print(f"Found {len(files)} files in {root}")
                    yield f"data: Found {len(files)} files in {root}\n\n"
                    
                    for file in files:
                        file_path = os.path.join(root, file)
                        
                        try:
                            # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶
                            should_skip, skip_reason = loader.should_skip_file(file_path)
                            if should_skip:
                                print(f"Skipping file: {file} ({skip_reason})")
                                yield f"data: Skipping file: {file} ({skip_reason})\n\n"
                                skipped_count += 1
                                continue
                            
                            print(f"Processing file: {file_path}")
                            yield f"data: Processing file: {file_path}\n\n"
                            
                            docs = loader.load_document(file_path)
                            print(f"Successfully loaded {len(docs)} document chunks from {file_path}")
                            yield f"data: Successfully loaded {len(docs)} document chunks from {file_path}\n\n"
                            documents.extend(docs)
                            processed_count += 1
                            
                        except ValueError as ve:
                            # å¤„ç†è·³è¿‡æ–‡ä»¶çš„æƒ…å†µï¼ˆç”±load_documentå†…éƒ¨æŠ›å‡ºï¼‰
                            if "Skipped file" in str(ve):
                                print(f"Skipping file: {file} ({str(ve)})")
                                yield f"data: Skipping file: {file} ({str(ve)})\n\n"
                                skipped_count += 1
                            else:
                                print(f"Unsupported file type {file_path}: {str(ve)}")
                                yield f"data: Unsupported file type {file_path}: {str(ve)}\n\n"
                                error_count += 1
                            continue
                        except Exception as e:
                            print(f"Error processing {file_path}: {str(e)}")
                            yield f"data: Error processing {file_path}: {str(e)}\n\n"
                            error_count += 1
                            continue
                
                # ğŸ”§ æ–°å¢ï¼šè¾“å‡ºå¤„ç†ç»Ÿè®¡
                print(f"Processing summary: {processed_count} processed, {skipped_count} skipped, {error_count} errors")
                yield f"data: Processing summary: {processed_count} processed, {skipped_count} skipped, {error_count} errors\n\n"
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£è¢«æˆåŠŸå¤„ç†
                if not documents:
                    print("No documents were processed successfully")
                    yield "data: No documents were processed successfully\n\n"
                    raise ValueError("No documents were processed successfully")
                
                # æ‰€æœ‰æ–‡æ¡£å¤„ç†å®Œæˆåï¼Œåˆ›å»ºå‘é‡å­˜å‚¨
                print(f"Creating vector store with {len(documents)} document chunks")
                yield f"data: Creating vector store with {len(documents)} document chunks\n\n"
                vector_store_manager.create_vectorstore(
                    documents,
                    vectorstore_path
                )
                print(f"Vector store successfully created and saved to {vectorstore_path}")
                yield f"data: Vector store successfully created and saved to {vectorstore_path}\n\n"
                
                # å‘é€æœ€ç»ˆç»“æœ
                result = {
                    "message": f"Successfully ingested {len(documents)} document chunks",
                    "documents_count": len(documents),
                    "vectorstore_path": vectorstore_path,
                    "stats": {
                        "processed": processed_count,
                        "skipped": skipped_count,
                        "errors": error_count
                    }
                }
                print(f"Successfully ingested {len(documents)} document chunks")
                yield f"data: {json.dumps(result)}\n\n"
                
            except Exception as e:
                import traceback
                error_trace = traceback.format_exc()
                error_msg = f"Document ingestion failed: {str(e)}\n{error_trace}"
                print(f"ERROR: {error_msg}")
                yield f"data: ERROR: {error_msg}\n\n"
                raise HTTPException(status_code=500, detail=error_msg)
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
    )





@router.post("/init")
async def init_project():
    """é¡¹ç›®åˆå§‹åŒ–æ¥å£ - æ›¿ä»£åŸæ¥çš„setup.pyåŠŸèƒ½"""
    try:
        # å¯¼å…¥åˆå§‹åŒ–é€»è¾‘
        from src.scripts.init_project import init_project as init_func
        
        init_func()
        return {"message": "Project initialized successfully"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Project initialization failed: {str(e)}")

@router.get("/health")
async def rag_health_check():
    """RAGæœåŠ¡å¥åº·æ£€æŸ¥"""
    try:
        # ç®€å•æ£€æŸ¥å…³é”®ç»„ä»¶æ˜¯å¦å¯ç”¨
        model = os.getenv("MODEL")
        vectorstore_path = os.getenv("VECTORSTORE_PATH")
        
        return {
            "status": "healthy", 
            "service": "RAG Query Service",
            "model": model,
            "vectorstore_path": vectorstore_path,
            "vectorstore_exists": os.path.exists(vectorstore_path) if vectorstore_path else False
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }
